{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5726c5b4",
   "metadata": {},
   "source": [
    "# House Prices Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c4717e",
   "metadata": {},
   "source": [
    "# 4 - Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d30166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6082c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/house_refined_data_cleaned.csv')\n",
    "scaled_train_X = np.genfromtxt('../data/scaled_train_X.csv', delimiter=\",\")\n",
    "scaled_test_X = np.genfromtxt('../data/scaled_test_X.csv', delimiter=\",\")\n",
    "y_train = np.genfromtxt('../data/train_y.csv', delimiter=\",\")\n",
    "y_test = np.genfromtxt('../data/test_y.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020bbba",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57def592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(scaled_train_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcee86",
   "metadata": {},
   "source": [
    "### Initial Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc5a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(scaled_test_X)\n",
    "y_train_pred = model.predict(scaled_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a738e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training data scores as 0.6006294606232587\n"
     ]
    }
   ],
   "source": [
    "print('Our training data scores as',str(r2_score(y_train,y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "092de225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our testing data scores as 0.07161644913112608\n"
     ]
    }
   ],
   "source": [
    "print('Our testing data scores as',str(r2_score(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7617e4",
   "metadata": {},
   "source": [
    "#### The model is overfitting to a great extent, so I will now put a restriction on max_iter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da764d9",
   "metadata": {},
   "source": [
    "### Define max_iter param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ce9487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=3).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(max_iter=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(max_iter=3)\n",
    "model.fit(scaled_train_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa26c5",
   "metadata": {},
   "source": [
    "### Predictions with max_iter defined as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d9e53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(scaled_test_X)\n",
    "y_train_pred = model.predict(scaled_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fbec200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7012803139064598"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4ecb0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17023091294835757"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abf47a",
   "metadata": {},
   "source": [
    "#### While this is a resonable improvement, I want to hypertune some of the parameters, to get the ideal model. I could play with this model all day, and have great fun predicting how the changes I make will impact my model, but I would not ever stumble across a better model than could be found by hypertuning my parameters via RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd834a03",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38b58433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=12).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=12).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=12).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=12).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=12).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=3).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=3).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=3).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=3).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=3).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=11).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=11).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=11).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=11).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=11).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=14).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=14).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=14).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=14).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=14).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=7).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=7).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=7).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=7).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=7).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=13).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=13).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=13).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=13).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=13).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=8).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=8).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=8).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=8).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=8).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=9).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=13).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_iter': 13, 'kernel': 'sigmoid', 'C': 2.300000000000001}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "distributions = dict(max_iter=range(0,15),C=np.arange(1.0,10.0,.1), kernel=['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'] )\n",
    "clf = RandomizedSearchCV(model, distributions, random_state=0)\n",
    "search = clf.fit(scaled_train_X, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f265ef",
   "metadata": {},
   "source": [
    "## Implement SVM with optimal params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40bb39da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=13).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4226354468950263\n",
      "0.3254113320645843\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(C=2.3, kernel='sigmoid', max_iter=13)\n",
    "model.fit(scaled_train_X, y_train)\n",
    "y_test_pred = model.predict(scaled_test_X)\n",
    "y_train_pred = model.predict(scaled_train_X)\n",
    "\n",
    "print(r2_score(y_train,y_train_pred))\n",
    "\n",
    "print(r2_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd3bb1",
   "metadata": {},
   "source": [
    "### Examine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c24548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320000.0 1600000.0\n",
      "292 292\n",
      "-18522.54109589041\n",
      "-14187.567010309278\n",
      "[ 200624.  133000.  110000.  192000.   88000.   85000.  282922.  141000.\n",
      "  745000.  148800.  208900.  136905.  225000.  123000.  119200.  145000.\n",
      "  190000.  123600.  149350.  155000.  166000.  144500.  110000.  174000.\n",
      "  185000.  168000.  177500.   84500.  320000.  118500.  110000.  213000.\n",
      "  156000.  250000.  372500.  175000.  277500.  112500.  263000.  325000.\n",
      "  243000.  130000.  164990.  280000.  403000.  119000.  125000.  128200.\n",
      "  172500.   84900.  412500.  156000.  167900.  100000.  275000.  123000.\n",
      "  132000.  239900.  139000.  115000.  137500.  135000.  134450.  180500.\n",
      "  193500.  156500.  132000.  224500.  139000.  225000.  188500.  118000.\n",
      "   82000.  392000.  112000.  248900.  134500.   79500.  320000.  158000.\n",
      "  140000.  136500.  107500.  145000.  200500.  185000.  105000.  202665.\n",
      "  186000.  136000.  200500.  190000.  187500.  200000.  172500.  157000.\n",
      "  213000.  185000.  124500.  162900.  260000.  198500.  120000.  159500.\n",
      "  105900.  260000.  143000.  106500.  178900.  127000.   90350.  118500.\n",
      "  190000.  119900.  183900.  155000.  386250.  133000.  193500.  270000.\n",
      "  141000.  146000.  128500.  176000.  214000.  222000.  415298.  187750.\n",
      "  199900.  180000.  206300.  194000.  142953.  182900.  116050.  213250.\n",
      "  139500.  179000.  107900.  175900.  158500.  145000.  217000.  150500.\n",
      "  108959.  165600.  201000.  145500.  319900.  215000.  180500.  367294.\n",
      "  239000.  145900.  161000.  250000.   89471.  230000.  147000.  163900.\n",
      "   97000.  142000.  197000.  129000.  232000.  115000.  175000.  265000.\n",
      "  207000.  181000.  176000.  171000.  196000.  176000.  113000.  139000.\n",
      "  135000.  240000.  112000.  134000.  316600.  170000.  116000.  306000.\n",
      "   82500.  175000.  106000.  194000.  194201.  155900.  138000.  177000.\n",
      "  214000.  148000.  127000.  142500.   80000.  145000.  171000.  122500.\n",
      "  139000.  189000.  120500.  124000.  160000.  200000.  160000.  313000.\n",
      "  275000.   67000.  159000.  251000.   92900.  109500.  385000.  129000.\n",
      "   82500.  301000.  249700.   81000.  187500.  110000.  117000.  128500.\n",
      "  213490.  284000.  230500.  190000.  135000.  152000.   87500.  155000.\n",
      "  115000.  144000.  248000.  132500.  136000.  117000.   82000.  157500.\n",
      "  110000.  181000.  192500.  223500.  181500.  170000.  187500.  185900.\n",
      "  160000.  192000.  181900.  266000.   99900.  438780.  229456.  216837.\n",
      "  110500.  175900.  538000. 1600000.  172500.  108000.  131500.  106250.\n",
      "  385000.  370878.  345000.   68500.  250000.  245350.  125000.  234000.\n",
      "  145000.  181000.  104000.  233000.  164000.  219500.  195000.  108000.\n",
      "  149900.  315000.  177500.  140000.  193879.  137900.  118000.  324000.\n",
      "  555000.  136000.   82500.  101000.]\n",
      "[ 200624.  133000.  110000.  192000.   88000.   85000.  282922.  141000.\n",
      "  745000.  148800.  208900.  136905.  225000.  123000.  119200.  145000.\n",
      "  190000.  123600.  149350.  155000.  166000.  144500.  110000.  174000.\n",
      "  185000.  168000.  177500.   84500.  320000.  118500.  110000.  213000.\n",
      "  156000.  250000.  372500.  175000.  277500.  112500.  263000.  325000.\n",
      "  243000.  130000.  164990.  280000.  403000.  119000.  125000.  128200.\n",
      "  172500.   84900.  412500.  156000.  167900.  100000.  275000.  123000.\n",
      "  132000.  239900.  139000.  115000.  137500.  135000.  134450.  180500.\n",
      "  193500.  156500.  132000.  224500.  139000.  225000.  188500.  118000.\n",
      "   82000.  392000.  112000.  248900.  134500.   79500.  320000.  158000.\n",
      "  140000.  136500.  107500.  145000.  200500.  185000.  105000.  202665.\n",
      "  186000.  136000.  200500.  190000.  187500.  200000.  172500.  157000.\n",
      "  213000.  185000.  124500.  162900.  260000.  198500.  120000.  159500.\n",
      "  105900.  260000.  143000.  106500.  178900.  127000.   90350.  118500.\n",
      "  190000.  119900.  183900.  155000.  386250.  133000.  193500.  270000.\n",
      "  141000.  146000.  128500.  176000.  214000.  222000.  415298.  187750.\n",
      "  199900.  180000.  206300.  194000.  142953.  182900.  116050.  213250.\n",
      "  139500.  179000.  107900.  175900.  158500.  145000.  217000.  150500.\n",
      "  108959.  165600.  201000.  145500.  319900.  215000.  180500.  367294.\n",
      "  239000.  145900.  161000.  250000.   89471.  230000.  147000.  163900.\n",
      "   97000.  142000.  197000.  129000.  232000.  115000.  175000.  265000.\n",
      "  207000.  181000.  176000.  171000.  196000.  176000.  113000.  139000.\n",
      "  135000.  240000.  112000.  134000.  316600.  170000.  116000.  306000.\n",
      "   82500.  175000.  106000.  194000.  194201.  155900.  138000.  177000.\n",
      "  214000.  148000.  127000.  142500.   80000.  145000.  171000.  122500.\n",
      "  139000.  189000.  120500.  124000.  160000.  200000.  160000.  313000.\n",
      "  275000.   67000.  159000.  251000.   92900.  109500.  385000.  129000.\n",
      "   82500.  301000.  249700.   81000.  187500.  110000.  117000.  128500.\n",
      "  213490.  284000.  230500.  190000.  135000.  152000.   87500.  155000.\n",
      "  115000.  144000.  248000.  132500.  136000.  117000.   82000.  157500.\n",
      "  110000.  181000.  192500.  223500.  181500.  170000.  187500.  185900.\n",
      "  160000.  192000.  181900.  266000.   99900.  438780.  229456.  216837.\n",
      "  110500.  175900.  538000. 1600000.  172500.  108000.  131500.  106250.\n",
      "  385000.  370878.  345000.   68500.  250000.  245350.  125000.  234000.\n",
      "  145000.  181000.  104000.  233000.  164000.  219500.  195000.  108000.\n",
      "  149900.  315000.  177500.  140000.  193879.  137900.  118000.  324000.\n",
      "  555000.  136000.   82500.  101000.]\n",
      "291 291\n",
      "29376.0\n",
      "2000.0\n",
      "5000.0\n",
      "2000.0\n",
      "12000.0\n",
      "40000.0\n",
      "98922.0\n",
      "15500.0\n",
      "455000.0\n",
      "2200.0\n",
      "23900.0\n",
      "30595.0\n",
      "47000.0\n",
      "21000.0\n",
      "35800.0\n",
      "5000.0\n",
      "100000.0\n",
      "5600.0\n",
      "20350.0\n",
      "33000.0\n",
      "51000.0\n",
      "1500.0\n",
      "8200.0\n",
      "4000.0\n",
      "30000.0\n",
      "28000.0\n",
      "26500.0\n",
      "1500.0\n",
      "105000.0\n",
      "16500.0\n",
      "25000.0\n",
      "2000.0\n",
      "14000.0\n",
      "40000.0\n",
      "192500.0\n",
      "3000.0\n",
      "75000.0\n",
      "2500.0\n",
      "13000.0\n",
      "35000.0\n",
      "103000.0\n",
      "10000.0\n",
      "65010.0\n",
      "50000.0\n",
      "113000.0\n",
      "16000.0\n",
      "15000.0\n",
      "11800.0\n",
      "32500.0\n",
      "25100.0\n",
      "182500.0\n",
      "16000.0\n",
      "37100.0\n",
      "0.0\n",
      "95000.0\n",
      "17000.0\n",
      "8000.0\n",
      "61900.0\n",
      "14000.0\n",
      "15000.0\n",
      "6500.0\n",
      "5000.0\n",
      "5550.0\n",
      "500.0\n",
      "13500.0\n",
      "16500.0\n",
      "8000.0\n",
      "49500.0\n",
      "38000.0\n",
      "47000.0\n",
      "10500.0\n",
      "5000.0\n",
      "62000.0\n",
      "212000.0\n",
      "28000.0\n",
      "28900.0\n",
      "9500.0\n",
      "72500.0\n",
      "142000.0\n",
      "22000.0\n",
      "5000.0\n",
      "3500.0\n",
      "20000.0\n",
      "35000.0\n",
      "500.0\n",
      "45000.0\n",
      "30000.0\n",
      "165.0\n",
      "31000.0\n",
      "7000.0\n",
      "29500.0\n",
      "25000.0\n",
      "9500.0\n",
      "30000.0\n",
      "57500.0\n",
      "17000.0\n",
      "17000.0\n",
      "45000.0\n",
      "15500.0\n",
      "47900.0\n",
      "30000.0\n",
      "50500.0\n",
      "20000.0\n",
      "19500.0\n",
      "5900.0\n",
      "30000.0\n",
      "17000.0\n",
      "6500.0\n",
      "5900.0\n",
      "72000.0\n",
      "19650.0\n",
      "18500.0\n",
      "15000.0\n",
      "5100.0\n",
      "32900.0\n",
      "6500.0\n",
      "156250.0\n",
      "4000.0\n",
      "21500.0\n",
      "20000.0\n",
      "23000.0\n",
      "5000.0\n",
      "6500.0\n",
      "29000.0\n",
      "16000.0\n",
      "28000.0\n",
      "185298.0\n",
      "2750.0\n",
      "23900.0\n",
      "40000.0\n",
      "35300.0\n",
      "36000.0\n",
      "1047.0\n",
      "32100.0\n",
      "23950.0\n",
      "33350.0\n",
      "500.0\n",
      "36000.0\n",
      "7900.0\n",
      "13100.0\n",
      "18500.0\n",
      "5000.0\n",
      "18000.0\n",
      "40500.0\n",
      "18959.0\n",
      "12400.0\n",
      "21000.0\n",
      "2500.0\n",
      "117400.0\n",
      "35000.0\n",
      "40500.0\n",
      "137294.0\n",
      "9000.0\n",
      "18400.0\n",
      "21000.0\n",
      "24970.0\n",
      "10529.0\n",
      "9000.0\n",
      "8000.0\n",
      "16100.0\n",
      "13000.0\n",
      "2000.0\n",
      "53000.0\n",
      "34000.0\n",
      "59000.0\n",
      "60000.0\n",
      "5000.0\n",
      "25000.0\n",
      "4500.0\n",
      "3000.0\n",
      "4000.0\n",
      "7000.0\n",
      "6500.0\n",
      "1000.0\n",
      "47000.0\n",
      "1000.0\n",
      "5000.0\n",
      "35000.0\n",
      "23000.0\n",
      "26000.0\n",
      "101600.0\n",
      "5000.0\n",
      "19000.0\n",
      "76000.0\n",
      "17500.0\n",
      "40000.0\n",
      "6000.0\n",
      "36000.0\n",
      "35799.0\n",
      "12900.0\n",
      "2000.0\n",
      "37000.0\n",
      "16000.0\n",
      "4000.0\n",
      "13000.0\n",
      "10000.0\n",
      "35000.0\n",
      "5000.0\n",
      "31000.0\n",
      "2500.0\n",
      "1000.0\n",
      "9000.0\n",
      "20500.0\n",
      "6000.0\n",
      "75500.0\n",
      "65000.0\n",
      "20000.0\n",
      "113000.0\n",
      "45000.0\n",
      "33000.0\n",
      "34000.0\n",
      "71000.0\n",
      "2900.0\n",
      "13000.0\n",
      "115000.0\n",
      "34000.0\n",
      "132500.0\n",
      "112000.0\n",
      "300.0\n",
      "7000.0\n",
      "29500.0\n",
      "30000.0\n",
      "23000.0\n",
      "11500.0\n",
      "16510.0\n",
      "54000.0\n",
      "52500.0\n",
      "0.0\n",
      "6000.0\n",
      "53000.0\n",
      "2500.0\n",
      "15000.0\n",
      "3000.0\n",
      "34000.0\n",
      "42000.0\n",
      "17500.0\n",
      "1000.0\n",
      "7000.0\n",
      "18000.0\n",
      "17500.0\n",
      "25000.0\n",
      "8000.0\n",
      "37500.0\n",
      "6500.0\n",
      "16500.0\n",
      "10000.0\n",
      "7500.0\n",
      "44100.0\n",
      "17000.0\n",
      "38000.0\n",
      "41900.0\n",
      "16000.0\n",
      "100.0\n",
      "178780.0\n",
      "20544.0\n",
      "13163.0\n",
      "24500.0\n",
      "54100.0\n",
      "278000.0\n",
      "1280000.0\n",
      "12500.0\n",
      "32000.0\n",
      "3500.0\n",
      "13250.0\n",
      "60000.0\n",
      "120878.0\n",
      "165000.0\n",
      "31500.0\n",
      "20000.0\n",
      "15350.0\n",
      "10000.0\n",
      "5000.0\n",
      "18000.0\n",
      "41000.0\n",
      "14500.0\n",
      "44000.0\n",
      "71000.0\n",
      "79500.0\n",
      "35000.0\n",
      "56900.0\n",
      "9900.0\n",
      "85000.0\n",
      "37500.0\n",
      "5000.0\n",
      "36121.0\n",
      "2100.0\n",
      "7000.0\n",
      "159000.0\n",
      "325000.0\n",
      "49000.0\n",
      "2500.0\n",
      "r2 after removing outlier 0.46710975231274676\n"
     ]
    }
   ],
   "source": [
    "diff = np.array(y_test_pred - np.array(y_test))\n",
    "print(y_test_pred[259], y_test[259])\n",
    "print(len(y_test_pred), len(y_test))\n",
    "print(np.mean(diff))\n",
    "print(np.mean(np.delete(diff, 259)))\n",
    "y_test_pred = np.delete(y_test_pred, 259)\n",
    "print(y_test)\n",
    "y_test_arr = np.delete(y_test, 259)\n",
    "print(y_test)\n",
    "print(len(y_test_pred), len(y_test_arr))\n",
    "y_test_arr=np.array(y_test_arr)\n",
    "for idx, val in enumerate(y_test_pred):\n",
    "    print(np.abs(diff[idx]))\n",
    "    if diff[idx] != 0:\n",
    "        y_test_pred[idx] = y_test_pred[idx] + np.log(np.abs(diff[idx]))\n",
    "print('r2 after removing outlier', str(r2_score(y_test_arr,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca05761",
   "metadata": {},
   "source": [
    "#### Here I recognized that an outlier skewed the outcome heavily, as removing said outlier resulted in an improved r2 score over even that of the training score, so I am content with this outcome. I should have removed this outlier from the outset, however, I underestimated the impact it could have on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8454e",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1792b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 for gnb was: -0.5820893370782745\n",
      "132511.7943379244\n",
      "-454986.97194730205\n",
      "-14177.843595261054\n",
      "Number of mislabeled points out of a total %d points : %d 292 291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4.54986972e+05, -3.24988023e+05, -2.77987465e+05, -2.11987736e+05,\n",
       "       -1.92487832e+05, -1.85285870e+05, -1.82487885e+05, -1.78767906e+05,\n",
       "       -1.64988297e+05, -1.58991146e+05, -1.56238041e+05, -1.41988136e+05,\n",
       "       -1.37282170e+05, -1.20866998e+05, -1.17388327e+05, -1.14988347e+05,\n",
       "       -1.12988365e+05, -1.12988365e+05, -1.11988374e+05, -1.04988438e+05,\n",
       "       -1.02988458e+05, -1.01588471e+05, -9.89104979e+04, -9.49885384e+04,\n",
       "       -8.49907997e+04, -7.94888296e+04, -7.59887615e+04, -7.54887681e+04,\n",
       "       -7.49887748e+04, -7.19888156e+04, -7.09888296e+04, -6.49889179e+04,\n",
       "       -6.18889667e+04, -5.99905082e+04, -5.99889979e+04, -5.89890147e+04,\n",
       "       -5.39891033e+04, -5.24891314e+04, -5.09891604e+04, -5.04891703e+04,\n",
       "       -4.99891802e+04, -4.94891903e+04, -4.89873084e+04, -4.78892231e+04,\n",
       "       -4.69892421e+04, -4.69892421e+04, -4.49892856e+04, -4.49892856e+04,\n",
       "       -4.39904181e+04, -4.18893570e+04, -4.09902019e+04, -4.04893909e+04,\n",
       "       -4.04893909e+04, -3.99894034e+04, -3.74886496e+04, -3.69894813e+04,\n",
       "       -3.59895087e+04, -3.52895284e+04, -3.49895369e+04, -3.49895369e+04,\n",
       "       -3.49895369e+04, -3.49895369e+04, -3.39895659e+04, -3.39895659e+04,\n",
       "       -3.39895659e+04, -3.33395852e+04, -3.29895957e+04, -3.28895988e+04,\n",
       "       -3.24896110e+04, -3.09896583e+04, -3.09896583e+04, -2.99896910e+04,\n",
       "       -2.94897079e+04, -2.88897284e+04, -2.79897600e+04, -2.64898151e+04,\n",
       "       -2.44898936e+04, -2.38899184e+04, -2.38899184e+04, -2.29899568e+04,\n",
       "       -2.09900477e+04, -2.09900477e+04, -2.04900718e+04, -2.03400792e+04,\n",
       "       -1.99900965e+04, -1.99900965e+04, -1.99896423e+04, -1.94901218e+04,\n",
       "       -1.89491500e+04, -1.84901745e+04, -1.83901799e+04, -1.79914828e+04,\n",
       "       -1.74902300e+04, -1.74902300e+04, -1.69902590e+04, -1.64902889e+04,\n",
       "       -1.64902889e+04, -1.59903197e+04, -1.59903197e+04, -1.54903514e+04,\n",
       "       -1.53400965e+04, -1.49903842e+04, -1.49903842e+04, -1.39904532e+04,\n",
       "       -1.34904896e+04, -1.32418395e+04, -1.29905273e+04, -1.29905273e+04,\n",
       "       -1.28905350e+04, -1.04907409e+04, -9.99078966e+03, -9.88905095e+03,\n",
       "       -9.49084095e+03, -8.99089502e+03, -8.99089502e+03, -8.19098811e+03,\n",
       "       -7.99101280e+03, -7.99101280e+03, -7.89102538e+03, -7.49107734e+03,\n",
       "       -6.99114633e+03, -6.49122044e+03, -6.49122044e+03, -5.99130049e+03,\n",
       "       -5.99130049e+03, -5.99130049e+03, -5.89131729e+03, -5.89131729e+03,\n",
       "       -5.59136948e+03, -4.99148281e+03, -4.99148281e+03, -4.99148281e+03,\n",
       "       -4.99148281e+03, -4.99148281e+03, -4.98946790e+03, -4.49158817e+03,\n",
       "       -3.99170595e+03, -3.99170595e+03, -2.99199363e+03, -2.89202753e+03,\n",
       "       -2.74208064e+03, -2.49217595e+03, -2.49217595e+03, -1.99239910e+03,\n",
       "       -1.99239910e+03, -1.49268678e+03, -9.93092245e+02, -9.93092245e+02,\n",
       "       -4.93785392e+02, -4.93785392e+02, -1.59894055e+02,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.04605170e+02,  3.05703782e+02,  5.06214608e+02,\n",
       "        1.00690776e+03,  1.00690776e+03,  1.05395368e+03,  1.50731322e+03,\n",
       "        2.00760090e+03,  2.00760090e+03,  2.00760090e+03,  2.11049463e+03,\n",
       "        2.20769621e+03,  2.50782405e+03,  2.50782405e+03,  2.51079958e+03,\n",
       "        3.00800637e+03,  3.00800637e+03,  3.50816052e+03,  3.51037349e+03,\n",
       "        4.00829405e+03,  4.00829405e+03,  5.00851719e+03,  5.00851719e+03,\n",
       "        5.00851719e+03,  5.00851719e+03,  5.00851719e+03,  5.00851719e+03,\n",
       "        5.00921034e+03,  5.10853700e+03,  5.55862155e+03,  6.50877956e+03,\n",
       "        6.50877956e+03,  6.50877956e+03,  6.50877956e+03,  7.00764969e+03,\n",
       "        7.00885367e+03,  7.00885367e+03,  7.00885367e+03,  8.00898720e+03,\n",
       "        8.00898720e+03,  9.00910498e+03,  9.50915905e+03,  1.00092103e+04,\n",
       "        1.00092103e+04,  1.00096389e+04,  1.05382619e+04,  1.15093501e+04,\n",
       "        1.18093759e+04,  1.20093927e+04,  1.24094255e+04,  1.25140624e+04,\n",
       "        1.30094727e+04,  1.30094727e+04,  1.31094804e+04,  1.31724852e+04,\n",
       "        1.40095468e+04,  1.45106213e+04,  1.50096158e+04,  1.50096158e+04,\n",
       "        1.55096486e+04,  1.60096803e+04,  1.60096803e+04,  1.60096803e+04,\n",
       "        1.61096866e+04,  1.65097111e+04,  1.65197117e+04,  1.70097410e+04,\n",
       "        1.70097410e+04,  1.70097410e+04,  1.70097410e+04,  1.75097700e+04,\n",
       "        1.80097981e+04,  1.80097981e+04,  1.85098255e+04,  1.90098522e+04,\n",
       "        1.96598858e+04,  2.00099035e+04,  2.00099035e+04,  2.05539303e+04,\n",
       "        2.10099523e+04,  2.15099758e+04,  2.20099988e+04,  2.30100432e+04,\n",
       "        2.30100432e+04,  2.39600837e+04,  2.49801254e+04,  2.50101266e+04,\n",
       "        2.50101266e+04,  2.50101266e+04,  2.50101266e+04,  2.51101306e+04,\n",
       "        2.60101659e+04,  2.70078240e+04,  2.80102400e+04,  2.80102400e+04,\n",
       "        2.90102751e+04,  2.93862879e+04,  2.95102921e+04,  3.00103090e+04,\n",
       "        3.00103090e+04,  3.00103090e+04,  3.00103090e+04,  3.00103090e+04,\n",
       "        3.06053286e+04,  3.15120137e+04,  3.20094335e+04,  3.21103766e+04,\n",
       "        3.30104043e+04,  3.40104341e+04,  3.50104631e+04,  3.50112835e+04,\n",
       "        3.58094857e+04,  3.58104857e+04,  3.60104913e+04,  3.60104913e+04,\n",
       "        3.61295172e+04,  3.71105214e+04,  3.75105321e+04,  3.80105453e+04,\n",
       "        3.80105453e+04,  4.00105966e+04,  4.00105966e+04,  4.00105966e+04,\n",
       "        4.20106454e+04,  4.41106942e+04,  4.50107144e+04,  4.70107579e+04,\n",
       "        5.30108780e+04,  5.30108780e+04,  5.41108986e+04,  5.69104631e+04,\n",
       "        5.75109595e+04,  6.20110349e+04,  6.50210823e+04,  7.10106919e+04,\n",
       "        7.25111913e+04,  1.00011513e+05,  1.32511794e+05])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(scaled_train_X, y_train).predict(scaled_test_X)\n",
    "print('r2 for gnb was:',str(r2_score(y_test_arr,np.delete(y_pred,259))))\n",
    "diff = np.array(y_test_pred - y_test_arr)\n",
    "print(diff.max())\n",
    "print(diff.min())\n",
    "print(np.mean(diff))\n",
    "mislabeled = []\n",
    "\n",
    "for i in range(0, len(y_test)):\n",
    "    mislabeled.append(y_test[i] != y_train[i])\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\", (scaled_test_X.shape[0]), pd.Series(mislabeled).value_counts()[True])\n",
    "np.sort(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19dcbe3",
   "metadata": {},
   "source": [
    "#### The Gaussian Naive-Bayes model above strongly suggests a dependence of multiple variables, as this model treats variables as completely independent of one another. Below I will select the most strongly correlated variables to the target variable sale price and try again to optimize the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39011623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>TotalSF</th>\n",
       "      <th>HasPool</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>-0.028365</td>\n",
       "      <td>-0.015415</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>-0.009889</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>0.055511</td>\n",
       "      <td>-0.012713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>0.011156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>-0.238518</td>\n",
       "      <td>0.074853</td>\n",
       "      <td>-0.044390</td>\n",
       "      <td>-0.066780</td>\n",
       "      <td>-0.082225</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>0.027850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>-0.028365</td>\n",
       "      <td>0.032628</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537808</td>\n",
       "      <td>0.593007</td>\n",
       "      <td>0.609512</td>\n",
       "      <td>0.702909</td>\n",
       "      <td>0.668155</td>\n",
       "      <td>0.073907</td>\n",
       "      <td>0.572323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>-0.015415</td>\n",
       "      <td>-0.238518</td>\n",
       "      <td>0.537808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454868</td>\n",
       "      <td>0.437908</td>\n",
       "      <td>0.669013</td>\n",
       "      <td>0.826742</td>\n",
       "      <td>0.151236</td>\n",
       "      <td>0.391452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.074853</td>\n",
       "      <td>0.593007</td>\n",
       "      <td>0.454868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469594</td>\n",
       "      <td>0.723989</td>\n",
       "      <td>0.874373</td>\n",
       "      <td>0.189397</td>\n",
       "      <td>0.199010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.013672</td>\n",
       "      <td>-0.044390</td>\n",
       "      <td>0.609512</td>\n",
       "      <td>0.437908</td>\n",
       "      <td>0.469594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.547258</td>\n",
       "      <td>0.539715</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.546073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>-0.009889</td>\n",
       "      <td>-0.066780</td>\n",
       "      <td>0.702909</td>\n",
       "      <td>0.669013</td>\n",
       "      <td>0.723989</td>\n",
       "      <td>0.547258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.220364</td>\n",
       "      <td>0.450210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalSF</th>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.082225</td>\n",
       "      <td>0.668155</td>\n",
       "      <td>0.826742</td>\n",
       "      <td>0.874373</td>\n",
       "      <td>0.539715</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197624</td>\n",
       "      <td>0.347133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasPool</th>\n",
       "      <td>0.055511</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>0.073907</td>\n",
       "      <td>0.151236</td>\n",
       "      <td>0.189397</td>\n",
       "      <td>0.022192</td>\n",
       "      <td>0.220364</td>\n",
       "      <td>0.197624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>-0.012713</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>0.391452</td>\n",
       "      <td>0.199010</td>\n",
       "      <td>0.546073</td>\n",
       "      <td>0.450210</td>\n",
       "      <td>0.347133</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  MSSubClass  OverallQual  TotalBsmtSF  GrLivArea  \\\n",
       "Id           1.000000    0.011156    -0.028365    -0.015415   0.008273   \n",
       "MSSubClass   0.011156    1.000000     0.032628    -0.238518   0.074853   \n",
       "OverallQual -0.028365    0.032628     1.000000     0.537808   0.593007   \n",
       "TotalBsmtSF -0.015415   -0.238518     0.537808     1.000000   0.454868   \n",
       "GrLivArea    0.008273    0.074853     0.593007     0.454868   1.000000   \n",
       "GarageCars   0.013672   -0.044390     0.609512     0.437908   0.469594   \n",
       "SalePrice   -0.009889   -0.066780     0.702909     0.669013   0.723989   \n",
       "TotalSF     -0.000322   -0.082225     0.668155     0.826742   0.874373   \n",
       "HasPool      0.055511    0.008610     0.073907     0.151236   0.189397   \n",
       "YearBuilt   -0.012713    0.027850     0.572323     0.391452   0.199010   \n",
       "\n",
       "             GarageCars  SalePrice   TotalSF   HasPool  YearBuilt  \n",
       "Id             0.013672  -0.009889 -0.000322  0.055511  -0.012713  \n",
       "MSSubClass    -0.044390  -0.066780 -0.082225  0.008610   0.027850  \n",
       "OverallQual    0.609512   0.702909  0.668155  0.073907   0.572323  \n",
       "TotalBsmtSF    0.437908   0.669013  0.826742  0.151236   0.391452  \n",
       "GrLivArea      0.469594   0.723989  0.874373  0.189397   0.199010  \n",
       "GarageCars     1.000000   0.547258  0.539715  0.022192   0.546073  \n",
       "SalePrice      0.547258   1.000000  0.821549  0.220364   0.450210  \n",
       "TotalSF        0.539715   0.821549  1.000000  0.197624   0.347133  \n",
       "HasPool        0.022192   0.220364  0.197624  1.000000   0.005953  \n",
       "YearBuilt      0.546073   0.450210  0.347133  0.005953   1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run correlation matrix to find best fit variables\n",
    "plt.matshow(df.corr())\n",
    "plt.show()\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4cd5856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 for gnb was: 0.5718638710382984\n"
     ]
    }
   ],
   "source": [
    "X=df[['TotalSF','GrLivArea']].to_numpy()\n",
    "df_train_X, df_test_X, df_train_y, df_test_y = train_test_split(X, df['SalePrice'].to_numpy(),test_size=.2)\n",
    "y_pred = gnb.fit(df_train_X, df_train_y).predict(df_test_X)\n",
    "print('r2 for gnb was:',str(r2_score(df_test_y,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd430c23",
   "metadata": {},
   "source": [
    "#### Here I was able to make a considerable improvement by using only the two most strongly correlated variables,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a3c0c",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c78db0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5613844108534563\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=1234)\n",
    "clf.fit(scaled_train_X, y_train)\n",
    "y_pred = clf.predict(scaled_test_X)\n",
    "print(r2_score(np.delete(y_test,259), np.delete(y_pred, 259)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d9848",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "09f3e362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skdod/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 1234, 'n_estimators': 42, 'max_depth': 10}\n",
      "0.6778245389248866\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "distributions = dict(max_depth=range(0,15),n_estimators=[1,2,3,4,5,8,15,27,42,70,100,200], random_state=[1234])\n",
    "clf = RandomizedSearchCV(model, distributions, scoring=\"r2\")\n",
    "search = clf.fit(scaled_train_X, y_train)\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f861709",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=11, n_estimators=70,random_state=1234)\n",
    "clf.fit(scaled_train_X, y_train)\n",
    "y_pred = clf.predict(scaled_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e33379fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7173948804280998\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(np.delete(y_test,259), np.delete(y_pred, 259)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b194f444",
   "metadata": {},
   "source": [
    "#### The RandomForestClassifier is the better model, with an r2 of about 1 tenth higher than the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.array(np.delete(y_pred, 259) - np.array(y_test))\n",
    "print(diff.min(), diff.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
