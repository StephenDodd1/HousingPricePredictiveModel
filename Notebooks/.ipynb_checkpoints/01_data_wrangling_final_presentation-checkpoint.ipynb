{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171004b3",
   "metadata": {},
   "source": [
    "# House Prices Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24414394",
   "metadata": {},
   "source": [
    "# 1 - Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy \n",
    "from scipy import stats\n",
    "\n",
    "from library.sb_utils import save_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd04ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ab132",
   "metadata": {},
   "source": [
    "## High level overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8006dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8055f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462170e",
   "metadata": {},
   "source": [
    "# Target variable : SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36e280",
   "metadata": {},
   "source": [
    "# <u>SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2b80c",
   "metadata": {},
   "source": [
    "## Sale Price Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['SalePrice'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b336a",
   "metadata": {},
   "source": [
    "*Our descriptive statistics show a fairly large range, but the interquartile range is approximately equal to the standard deviation. This would indicate that our data is fairly well clustered.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce6e7d",
   "metadata": {},
   "source": [
    "## Figure - Counts by Sale Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "ax = df['SalePrice'].hist(bins=20)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_xlabel('SalePrice')\n",
    "ax.set_title('Sale Price Distribution', size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8493e",
   "metadata": {},
   "source": [
    "*The data have a Poisson distribution with a positive skew.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3eaf4d",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4915cd9",
   "metadata": {},
   "source": [
    "**We need to start by narrowing the scope of variables we are looking at. There are too many of them. I will attempt to go about accomplishing this by testing for statistical significance, and removing that which I cannot confidently reject the null hypothesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473acde8",
   "metadata": {},
   "source": [
    "# a. <u>LotArea\n",
    "**Hypothesis:** Lot area will have a significant correlation with Sale Price.<br><br>\n",
    "*I'm starting here because my assumption is that a home on a large piece of land should naturally be more expensive, as it includes the price of the land it sits on. I realize that this could vary dramatically depending on where the land is located. Ie. In Los Angeles or New York this might be much more significant than rural US or Canada.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d455e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "ax = df['LotArea'].hist(bins=25)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_xlabel('LotArea')\n",
    "ax.set_title('Lot Area Distribution', size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c98c44",
   "metadata": {},
   "source": [
    "*The LotArea data have an approximately logarithmic distribution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879a91b",
   "metadata": {},
   "source": [
    "### Figure a.1 - Correlation of LotArea and SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff81ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(df.SalePrice, sm.add_constant(df.LotArea))\n",
    "p = model.fit().params\n",
    "x = df.LotArea\n",
    "ax = df.plot(x='LotArea', y='SalePrice', kind='scatter', alpha = 0.1)\n",
    "ax.plot(x, p.const + p.LotArea * x, c='r')\n",
    "plt.title('Sale Price x Lot Area',size=18)\n",
    "plt.rc(\"figure\", figsize=(8,5))\n",
    "plt.show()\n",
    "print (\"correlation :\",scipy.stats.pearsonr(df.SalePrice, df.LotArea))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730612d0",
   "metadata": {},
   "source": [
    "*There is a clearly significant correlation between sale price and lot area, as the p-value is well below the generally accepted threshold of .05.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce7a4d",
   "metadata": {},
   "source": [
    "### Figure a.2 - Histogram of LotArea and SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8233f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = df['LotArea'].hist(bins=25, histtype='step', density=True)\n",
    "bx = df['SalePrice'].hist(bins=50, histtype='step',density=True)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Number ')\n",
    "ax.set_xlabel('LotArea')\n",
    "ax.set_title('Sale Price x Lot Area')\n",
    "plt.show()\n",
    "pd.DataFrame(df['LotArea'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df130d9",
   "metadata": {},
   "source": [
    "**Despite the presence of a statistically significant correlation between LotArea and SalePrice, and the fact that both appear to be Poisson distributions, the skew is a little different, as the LotArea seems to be nearly logarithmic. So while the correlation is there, I believe there will be a better variable to explain the variation in our data. As you see in the chart above, the LotArea values are concentrated at lower values. The distributions are nearly logarithmic for LotArea and something closer to a Gaussian distribution in the SalePrice variable. I believe the correlation may be explained by the fact that a smaller lot limits the size of the house, such that larger homes can't fit on them, and that to area of the home itself is the major driver in price, and explains the majority of variation in LotArea. For this reason, I don't feel that I can confidently reject the null hypothesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bea925",
   "metadata": {},
   "source": [
    "# c. <u>Examination of Total Area</u>\n",
    "**Hypothesis:** Measures of area will have a statistically significant effect on Sale Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "ax = df['1stFlrSF'].hist(bins=20)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_xlabel('First Floor Area')\n",
    "ax.set_title('First Floor Area Distribution', size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f702fe",
   "metadata": {},
   "source": [
    "*Immediately I notice, that this chart looks similar to the distribution of SalePrice.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df66cd",
   "metadata": {},
   "source": [
    "### Figure c.1 - First Floor Area - SalePrice correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_model = sm.OLS(df.SalePrice, sm.add_constant(df['1stFlrSF']))\n",
    "sf_p = sf_model.fit().params\n",
    "x = df['1stFlrSF']\n",
    "ax = df.plot(x='1stFlrSF', y='SalePrice', kind='scatter', alpha = 0.1)\n",
    "ax.plot(x, sf_p.const + sf_p['1stFlrSF'] * x, c='r')\n",
    "plt.show()\n",
    "print (\"correlation :\",scipy.stats.pearsonr(df.SalePrice, df['1stFlrSF']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc0e87",
   "metadata": {},
   "source": [
    "### Figure c.2 - Second Floor Area(non-zero values) - SalePrice correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01412065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf2_df = pd.DataFrame(df[df['2ndFlrSF'] !=0])\n",
    "sf2_model = sm.OLS(sf2_df.SalePrice, sm.add_constant(sf2_df['2ndFlrSF']))\n",
    "sf2_p = sf2_model.fit().params\n",
    "# generate x-values for your regression line (two is sufficient)\n",
    "x = sf2_df['2ndFlrSF']\n",
    "# scatter-plot data\n",
    "ax = sf2_df.plot(x='2ndFlrSF', y='SalePrice', kind='scatter', alpha = 0.1)\n",
    "# plot regression line on the same axes, set x-axis limits\n",
    "ax.plot(x, sf2_p.const + sf2_p['2ndFlrSF'] * x, c='r')\n",
    "plt.show()\n",
    "print (\"correlation :\",scipy.stats.pearsonr(sf2_df.SalePrice, sf2_df['2ndFlrSF']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d4288",
   "metadata": {},
   "source": [
    "*What stands out about these two scatter plots is that they share very similar correlation coefficients. So I will combine them to get a single column of TotalSF.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c90ff",
   "metadata": {},
   "source": [
    "### Combine the 1stFlrSF and 2ndFlrSF columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c04549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalSF'] = df['1stFlrSF'] + df['2ndFlrSF']\n",
    "df.drop(columns=['1stFlrSF','2ndFlrSF'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d41b6f4",
   "metadata": {},
   "source": [
    "### Figure c.3 - Total Area Correlation to SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7341ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_tot_model = sm.OLS(df.SalePrice, sm.add_constant(df['TotalSF']))\n",
    "sf_tot_p = sf_tot_model.fit().params\n",
    "# generate x-values for your regression line (two is sufficient)\n",
    "x = df['TotalSF']\n",
    "# scatter-plot data\n",
    "ax = df.plot(x='TotalSF', y='SalePrice', kind='scatter', alpha = 0.1)\n",
    "# plot regression line on the same axes, set x-axis limits\n",
    "ax.plot(x, sf_tot_p.const + sf_tot_p['TotalSF'] * x,c='r')\n",
    "plt.show()\n",
    "print (\"correlation :\",scipy.stats.pearsonr(df.SalePrice, df['TotalSF']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29529c",
   "metadata": {},
   "source": [
    "*Notice this correlation is steeper than in either of the previous two, with a greater significance as demonstrated by the p-values than either the first or second floor area alone.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45032c25",
   "metadata": {},
   "source": [
    "*I'm now going to look into basement area columns. I will either combine them with together or with TotalSF.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83f66e",
   "metadata": {},
   "source": [
    "### Figure c.4 - Correlation between SalePrice and Finished Basement size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1260ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfb_df = pd.DataFrame(df[df['BsmtFinSF1'] !=0])\n",
    "sfb_model = sm.OLS(sfb_df.SalePrice, sm.add_constant(sfb_df['BsmtFinSF1']))\n",
    "sfb_p = sfb_model.fit().params\n",
    "x = sfb_df['BsmtFinSF1']\n",
    "ax = sfb_df.plot(x='BsmtFinSF1', y='SalePrice', kind='scatter', alpha = 0.1)\n",
    "ax.plot(x, sfb_p.const + sfb_p['BsmtFinSF1'] * x, c='r')\n",
    "plt.show()\n",
    "print(\"correlation :\",scipy.stats.pearsonr(sfb_df.SalePrice, sfb_df['BsmtFinSF1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951984e",
   "metadata": {},
   "source": [
    "### Figure c.5 - Correlation between Finished Basement Area and Total Square footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f142e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf2_df = pd.DataFrame(df[df['BsmtFinSF1'] !=0])\n",
    "sf2_model = sm.OLS(sf2_df.TotalSF, sm.add_constant(sf2_df['BsmtFinSF1']))\n",
    "sf2_p = sf2_model.fit().params\n",
    "x = sf2_df['BsmtFinSF1']\n",
    "ax = sf2_df.plot(x='BsmtFinSF1', y='TotalSF', kind='scatter', alpha = 0.1)\n",
    "ax.plot(x, sf2_p.const + sf2_p['BsmtFinSF1'] * x, c='r')\n",
    "plt.show()\n",
    "print (\"correlation :\",scipy.stats.pearsonr(sf2_df.TotalSF, sf2_df['BsmtFinSF1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ce9b9",
   "metadata": {},
   "source": [
    "### Figure c.6 - Correlation of Unfinished Basement Area and SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfub_df = pd.DataFrame(df[df['BsmtUnfSF'] !=0])\n",
    "sfub_model = sm.OLS(sfub_df.SalePrice, sm.add_constant(sfub_df['BsmtUnfSF']))\n",
    "sfub_p = sfub_model.fit().params\n",
    "x = sfub_df['BsmtUnfSF']\n",
    "ax = sfub_df.plot(x='BsmtUnfSF', y='SalePrice', kind='scatter', alpha = 0.1)\n",
    "ax.plot(x, sfub_p.const + sfub_p['BsmtUnfSF'] * x, c='r')\n",
    "plt.show()\n",
    "print (\"correlation :\",scipy.stats.pearsonr(sfub_df.SalePrice, sfub_df['BsmtUnfSF']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a5832",
   "metadata": {},
   "source": [
    "### Figure c.7 - Correlation of Unfinished Basement Area and LotArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2dcbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfub_model = sm.OLS(sfub_df.TotalSF, sm.add_constant(sfub_df['BsmtUnfSF']))\n",
    "sfub_p = sfub_model.fit().params\n",
    "x = sfub_df['BsmtUnfSF']\n",
    "ax = sfub_df.plot(x='BsmtUnfSF', y='TotalSF', kind='scatter', alpha = 0.1)\n",
    "ax.plot(x, sfub_p.const + sfub_p['BsmtUnfSF'] * x, c='r')\n",
    "plt.show()\n",
    "print (\"correlation :\",scipy.stats.pearsonr(sfub_df.TotalSF, sfub_df['BsmtUnfSF']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e912e7",
   "metadata": {},
   "source": [
    "*What I notice here is that there is a slightly similar, and statistically significant relationship between the type and size of basement and total area, and also sale price. Finished basements have a stronger correlation on both Sale Price and TotalSF, which seems to me indicative of the fact that the correlation is a function of that which exists between TotalSF and SalePrice. I will explore this below.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec136e8",
   "metadata": {},
   "source": [
    "### Figure c.8 - Correlation between TotalSF and SalePrice grouped by Basement type, among homes with basements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df['BsmtUnfSF'] > 0].append(df[df['BsmtFinSF1'] > 0])\n",
    "model = sm.OLS(temp_df.SalePrice, sm.add_constant(temp_df.TotalSF))\n",
    "colors = np.where(temp_df.BsmtUnfSF > 0,'skyblue','blue')\n",
    "transparency = np.where(temp_df.BsmtUnfSF > 0,.1,1)\n",
    "p = model.fit().params\n",
    "x = temp_df.TotalSF\n",
    "ax = temp_df.plot(x='TotalSF', y='SalePrice', kind='scatter', alpha=transparency, c=colors)\n",
    "xline= temp_df.TotalSF.mean()\n",
    "plt.axvline(x = xline, color = 'k', label = '',linestyle='--')\n",
    "y= p.TotalSF * xline + p.const\n",
    "plt.axhline(y = y, color = 'k', label = '',linestyle='--')\n",
    "ax.plot(x, p.const + p.TotalSF * x, c='r')\n",
    "plt.title('Sale Price x TotalSF by Basement Type',size=18)\n",
    "plt.rc(\"figure\", figsize=(8,5))\n",
    "plt.show()\n",
    "print (\"correlation :\",scipy.stats.pearsonr(temp_df.SalePrice, temp_df.TotalSF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4828020",
   "metadata": {},
   "source": [
    "*As previously thought, there is a strong, and statistically significant relationship between SalePrice and TotalSF.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67832e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unfinished basement mean SalePrice:  \" + \"\\033[1;48;34m$ {:,.2f}\".format(df[df['BsmtUnfSF'] != 0]['SalePrice'].mean()))\n",
    "print(\"\\033[mNo basement mean SalePrice:  \" + \"\\033[1;48;34m$ {:,.2f}\".format(df[(df['BsmtUnfSF'] == 0) & (df['BsmtFinSF1'] == 0)]['SalePrice'].mean()))\n",
    "print(\"\\033[mFinished basement mean SalePrice:  \" + \"\\033[1;48;34m$ {:,.2f}\".format(df[df['BsmtFinSF1'] != 0]['SalePrice'].mean()) + os.linesep)\n",
    "\n",
    "print(\"\\033[mUnfinished basement mean SF:  \" + \"\\033[1;48;34m {:,.0f}\".format(df[df['BsmtUnfSF'] != 0]['TotalSF'].mean()))\n",
    "print(\"\\033[mNo basement mean SF:  \" + \"\\033[1;48;34m {:,.0f}\".format(df[(df['BsmtUnfSF'] == 0) & (df['BsmtFinSF1'] == 0)]['TotalSF'].mean()))\n",
    "print(\"\\033[mFinished basement mean SF:  \" + \"\\033[1;48;34m {:,.0f}\".format(df[df['BsmtFinSF1'] != 0]['TotalSF'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8ec89",
   "metadata": {},
   "source": [
    "*The means shown above seem to indicate that the difference between the means of homes with basements, and those without basements is significant, and also similar. Looking at the mean area, homes with basements are larger, but not even 20% larger on average. where the average price is approx. 80% greater. With this in mind, I will add the basement area to the TotalSF column.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f60172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm going to combine the Finished and Unfinished Basement data with the TotalSF column.\n",
    "print(df['TotalSF'].mean())\n",
    "df['TotalSF'] = df['TotalSF'] + df['BsmtUnfSF'] + df['BsmtFinSF1'] + df['BsmtFinSF2']\n",
    "print(df['TotalSF'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f8f04",
   "metadata": {},
   "source": [
    "### Figure c.9 - Correlation of SalePrice and TotalSF grouped by basement type with basement area added to TotalSF, excludes observations with no basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d9da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df['BsmtUnfSF'] > 0].append(df[df['BsmtFinSF1'] > 0])\n",
    "model = sm.OLS(temp_df.SalePrice, sm.add_constant(temp_df.TotalSF))\n",
    "colors = np.where(temp_df.BsmtUnfSF > 0,'skyblue','blue')\n",
    "transparency = np.where(temp_df.BsmtUnfSF > 0,.1,1)\n",
    "p = model.fit().params\n",
    "x = temp_df.TotalSF\n",
    "ax = temp_df.plot(x='TotalSF', y='SalePrice', kind='scatter', alpha=transparency, c=colors)\n",
    "ax.plot(x, p.const + p.TotalSF * x, c='r')\n",
    "xline= temp_df.TotalSF.mean()\n",
    "plt.axvline(x = xline, color = 'k', label = '',linestyle='--')\n",
    "y= p.TotalSF * xline + p.const\n",
    "plt.axhline(y = y, color = 'k', label = '',linestyle='--')\n",
    "plt.title('Sale Price x TotalSF by Basement Type',size=18)\n",
    "plt.rc(\"figure\", figsize=(8,5))\n",
    "plt.show()\n",
    "print (\"correlation :\",scipy.stats.pearsonr(temp_df.SalePrice, temp_df.TotalSF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baca04b",
   "metadata": {},
   "source": [
    "*We see that by adding the basement areas to our column TotalSF, the resultant dataset results in a greater explaination of variance.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68713f91",
   "metadata": {},
   "source": [
    "### Figure c.10 - Correlation of SalePrice to TotalSF with basement areas added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dedb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_tot_model = sm.OLS(df.SalePrice, sm.add_constant(df['TotalSF']))\n",
    "sf_tot_p = sf_tot_model.fit().params\n",
    "# generate x-values for your regression line (two is sufficient)\n",
    "x = df['TotalSF']\n",
    "# scatter-plot data\n",
    "ax = df.plot(x='TotalSF', y='SalePrice', kind='scatter', alpha = 0.1)\n",
    "# plot regression line on the same axes, set x-axis limits\n",
    "ax.plot(x, sf_tot_p.const + sf_tot_p['TotalSF'] * x,c='r')\n",
    "plt.show()\n",
    "print(\"correlation :\",scipy.stats.pearsonr(df.SalePrice, df['TotalSF']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a85b25f",
   "metadata": {},
   "source": [
    "**In this section we determined that TotalSF with basement area included is very highly statistically significantly correlated to our target variable, SalePrice. As seen above, the our p-value is slightly larger than it was when we excluded homes without a basement, but still very small with Total Area being defined as the sum of the ares of the first floor, second floor, and basement areas. With this, we can reject the null hypothesis and confidently assert that the correlation between TotalSF, as defined above, and SalePrice is statiscally significant, and explains a lot of the variance in our data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c332fd",
   "metadata": {},
   "source": [
    "# f. <u>Overview of the columns with integer data types</u>\n",
    "**Hypothesis :** There will be some variables in the dataset, beyond those we've already defined, that will be statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('int64').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43deec81",
   "metadata": {},
   "source": [
    "### Taking another look into the descriptive statistics for SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816420a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Range, mean and median of home values\n",
    "print('\\033[4mRange of prices:\\033[m' + os.linesep + '\\033[m\\n\\033[1;48;34m$' + str(df['SalePrice'].min()) + ' - $' + str(df['SalePrice'].max()))\n",
    "print('\\n' + '\\033[mMean: \\033[1;48;34m$' + \"{:,.2f}\".format(df['SalePrice'].mean()))\n",
    "print('\\033[mMedian: \\033[1;48;34m$' + \"{:,.2f}\".format(df['SalePrice'].median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b766726",
   "metadata": {},
   "source": [
    "### Loop over all of the int datatypes and examine the correlations in those columns with SalePrice, removing those with small correlation coefficients, which are indicative of explaining less of the variation in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39b3ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, column in enumerate(df.select_dtypes('int64').columns):\n",
    "    if(column not in ['Id', 'SalePrice', 'MSSubClass','MSZoning', 'TotalSF']):\n",
    "        col_model = sm.OLS(df.SalePrice, sm.add_constant(df[column]))\n",
    "        col_p = sfb_model.fit().params\n",
    "        corrcoef = scipy.stats.pearsonr(df.SalePrice, df[column])\n",
    "        if(np.abs(corrcoef[0]) > .7):\n",
    "            col=col_p.iloc[1]\n",
    "            x = df[column]\n",
    "            ax = df.plot(x=column, y='SalePrice', kind='scatter', alpha = 0.1)\n",
    "            ax.plot(x,col_p.const + col * x, c='r')\n",
    "            plt.title('SalePrice x ' + column + ' Correlation')\n",
    "            print(column, \" correlation : \",corrcoef)\n",
    "        else: \n",
    "            df.drop(columns=[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da1500",
   "metadata": {},
   "source": [
    "**We have narrowed down a good list of variables to lok into here. I can confidently reject the null hypothesis, as there are several variables that are significant. Note: Above, we have trendlines that are relatively flat within due to the presence of categorical values as integers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e77ade",
   "metadata": {},
   "source": [
    "# g. <u>Overview of the columns with categorical data types</u>\n",
    "**Hypothesis :** There will be some variables in the dataset, beyond those we've already defined, that will be statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('object').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d9b4b",
   "metadata": {},
   "source": [
    "### How many null values are there per column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ed3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_null_columns = {}\n",
    "for column in df.columns:\n",
    "    if(len(df[df[column].isnull()]) > 0):\n",
    "        find_null_columns[column] = len(df[df[column].isnull()])\n",
    "print('Number of null values:' + os.linesep)\n",
    "for k,v in sorted(find_null_columns.items(), key=lambda x: x[1], reverse=True):\n",
    "    print('\\033[m ' + k + ': \\033[1;48;34m' + str(v) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff80eae",
   "metadata": {},
   "source": [
    "*There is such little data on pools, I want to remove pool related columns, only after looking at the data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793beff3",
   "metadata": {},
   "source": [
    "# h. <u>Examine pool related columns</u>\n",
    "**Hypothesis :** There will be some variables in the dataset, beyond those we've already defined, that will be statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e79e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "df.PoolArea.replace(to_replace=np.nan, value=0, inplace=True)\n",
    "ax = df['PoolArea'].hist(bins=20)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_xlabel('Pool Area')\n",
    "ax.set_title('Pool Area Distribution', size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1;48;34mList of the PoolArea of pools and SalePrice of associated homes: \\033[m',os.linesep)\n",
    "print(str(df[df['PoolArea'] > 0]['PoolArea']) + os.linesep*2 + str(df[df['PoolArea'] > 0]['SalePrice']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f719041",
   "metadata": {},
   "source": [
    "*I notice an interesting trend in that pools are associated with higher sales prices.\n",
    "With that said, I don't think it tells much in terms of size, and with such little pool data,\n",
    "I believe the most important factor is whether the home has a pool or not, and that may be\n",
    "significant, therefore I will remove these values and simply add a column HasPool boolean.\n",
    "In the event that I later find that pools are a significant explanation of outliers, then I \n",
    "may remove those observations from the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df['PoolQC'].unique())\n",
    "df['HasPool'] = df['PoolQC'].isin(['Ex','Fa','Gd'])\n",
    "print(df.shape)\n",
    "df.drop(columns=['PoolQC','PoolArea'], inplace=True)\n",
    "print(len(df[df['HasPool']]))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b0207",
   "metadata": {},
   "source": [
    "### T-test for HasPool and SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9cc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs1=df[df['HasPool'] == True]['SalePrice']\n",
    "rvs2=df[df['HasPool'] == False]['SalePrice']\n",
    "stats.ttest_ind(rvs1, rvs2)\n",
    "### TODO: Look into chi-squared and ANOVA.\n",
    "### remove one with smallest sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d91ae",
   "metadata": {},
   "source": [
    "**The ttest indicates that HasPool is statistically significant, so we will reject the null hypothesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1837d8d",
   "metadata": {},
   "source": [
    "# <u>Overview of the remaining columns</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2e213",
   "metadata": {},
   "source": [
    "*Another look at how our data is shaping up after removing many columns to decide what to do next.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c79c5",
   "metadata": {},
   "source": [
    "*I'm also going to look into the values of MiscFeature to see if there may be enough data to analyze.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbcc331",
   "metadata": {},
   "source": [
    "# o. <u>MasVnrArea</u>\n",
    "**Hypothesis:** MasVnrArea will have a statistically significant impact on SalePrice, our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "df['Electrical'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "df['MasVnrArea'].replace(to_replace=np.nan, value=0.0, inplace=True)\n",
    "print(df[df['MasVnrArea'] > 2]['MasVnrArea'].count())\n",
    "print(\"${:,.0f}\".format(df[df['MasVnrArea'] > 2]['SalePrice'].mean()))\n",
    "print(\"${:,.0f}\".format(df[df['MasVnrArea'] <= 2]['SalePrice'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baecdece",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['MasVnrArea'] > 2]['SalePrice'].mean())\n",
    "temp_df = pd.DataFrame()\n",
    "temp_df['MasVnrArea>2'] = df['MasVnrArea'] > 2\n",
    "temp_df['SalePrice>mean'] = df['SalePrice'] > df['SalePrice'].mean()\n",
    "print(temp_df)\n",
    "contigency_pct = pd.crosstab(temp_df['SalePrice>mean'], temp_df['MasVnrArea>2'], normalize='index')\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(contigency_pct, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee60b72a",
   "metadata": {},
   "source": [
    "**It appears that MasVnrArea is not strongly correlated to higher values, therefore I am unable to reject the null hypothesis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6a730",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# regress \"expression\" onto \"motifScore\" (plus an intercept)\n",
    "model = sm.OLS(df.SalePrice, sm.add_constant(df.MasVnrArea))\n",
    "# p = model.fit().params\n",
    "# generate x-values for your regression line (two is sufficient)\n",
    "x = df.SalePrice\n",
    "# scatter-plot data\n",
    "ax = df.plot(x='MasVnrArea', y='SalePrice', kind='scatter')\n",
    "# plot regression line on the same axes, set x-axis limits\n",
    "# ax.plot(x, p.const + p.SalePrice* x)\n",
    "print (\"correlation :\",scipy.stats.pearsonr(df.MasVnrArea, df.SalePrice) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadbfa04",
   "metadata": {},
   "source": [
    "*It would appear that we no longer have any null values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ba8df",
   "metadata": {},
   "source": [
    "# <u>Wrap up data wrangling, ensuring the variable remaining are statistically significant.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc36646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned data\n",
    "df = pd.read_csv('../data/house_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ece28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df.select_dtypes('int64').corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <u>Wrap up data wrangling, ensuring the variable remaining are statistically significant.</u>\n",
    "\n",
    "corr = df.select_dtypes('int64').corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
