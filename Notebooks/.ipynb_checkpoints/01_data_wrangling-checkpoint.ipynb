{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04e41e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'library'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qp/hgh__lqs1dz1wk35m_9mqmn40000gn/T/ipykernel_20578/1170367580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msb_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'library'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from library.sb_utils import save_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd04ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8055f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8006dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes('int64').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7510b5ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qp/hgh__lqs1dz1wk35m_9mqmn40000gn/T/ipykernel_20578/3220829351.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.select_dtypes('object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ed3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many null values are there per column?\n",
    "find_null_columns = {}\n",
    "for column in data.columns:\n",
    "    if(len(data[data[column].isnull()]) > 0):\n",
    "        find_null_columns[column] = len(data[data[column].isnull()])\n",
    "print('Number of null values:' + os.linesep)\n",
    "for k,v in sorted(find_null_columns.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(k + ': ' + str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is such little data on pools, I want to remove pool related columns, only after looking at the data.\n",
    "print(str(data[data['PoolArea'] > 0]['PoolArea']) + os.linesep*2 + str(data[data['PoolArea'] > 0]['SalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I notice an interesting trend in that pools are associated with higher sales prices.\n",
    "#With that said, I don't think it tells much in terms of size, and with such little pool data,\n",
    "#I believe the most important factor is whether the home has a pool or not, and that may be\n",
    "#significant, therefore I will remove these values and simply add a column HasPool boolean.\n",
    "#In the event that I later find that pools are a significant explanation of outliers, then I \n",
    "#may remove those observations from the dataset.\n",
    "print(data.shape)\n",
    "print(data['PoolQC'].unique())\n",
    "data['HasPool'] = data['PoolQC'].isin(['Ex','Fa','Gd'])\n",
    "print(data.shape)\n",
    "data.drop(columns=['PoolQC','PoolArea'], inplace=True)\n",
    "print(len(data[data['HasPool']]))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm also going to look into the values of MiscFeature to see if there may be enough data to analyze.\n",
    "print(data['MiscFeature'].unique())\n",
    "#The greatest concern I have with this column is 'Other', so I want to see how frequent it appears.\n",
    "print(data[data['MiscFeature'] == 'Othr']['MiscFeature'].count())\n",
    "#Because there are only two, I'm wondering how much those two will skew the data.\n",
    "print(data[data['MiscFeature'] == 'Othr']['SalePrice'])\n",
    "#I believe these could be negative impacts on the sales price, though we can't be \n",
    "#certain, given the low saleprice of each.\n",
    "#Additionally, there doesn't seem to be any quality indicators for these values, so I will remove this column.\n",
    "\n",
    "data.drop(columns=['MiscFeature'], inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b363934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the MiscVal column has my attention, I will examine it.\n",
    "print(data['MiscVal'].unique())\n",
    "#The greatest concern I have with this column is 'Other', so I want to see how frequent it appears.\n",
    "print(data[data['MiscVal'] != 0]['MiscVal'].count())\n",
    "#Because there are only two, I'm wondering how much those two will skew the data.\n",
    "print(\"{:.2f}\".format(data[data['MiscVal'] != 0]['SalePrice'].mean()))\n",
    "#I see the mean of these homes that have miscellaneous features are somewhat low, and the majority\n",
    "#of observations do not have any value here, so I will remove it.\n",
    "data.drop(columns=['MiscVal'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is also a lot of missing data for fences, so I'm gonna see what types of values we have.\n",
    "print(data['Fence'].unique())\n",
    "#I didn't know what these meant, so I turned to the documentation. It turns out this indicates \n",
    "#mostly a level of privacy, and might be better as a boolean. Another interesting fact might be\n",
    "#a correlation between the home type and whether it has a fence. For example, rowHomes may have \n",
    "#small fences, condo's may have none at all. I'm thinking that any correlation between fence and\n",
    "#price may correspond to a type of housing, and as about 4/5ths of the homes have no fence data\n",
    "#listed, I believe the best move is to remove this column.\n",
    "data.drop(columns=['Fence'], inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6c639b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qp/hgh__lqs1dz1wk35m_9mqmn40000gn/T/ipykernel_20578/751905355.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#How many null values are there per column?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfind_null_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfind_null_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#How many null values are there per column?\n",
    "find_null_columns = {}\n",
    "for column in data.columns:\n",
    "    if(len(data[data[column].isnull()]) > 0):\n",
    "        find_null_columns[column] = len(data[data[column].isnull()])\n",
    "print('Number of null values:' + os.linesep)\n",
    "for k,v in sorted(find_null_columns.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(k + ': ' + str(v))\n",
    "#I still see alley's are the biggest row of null values, and I will look into those\n",
    "#in more detail next. I don't know much about alleys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Range, mean and median of home values\n",
    "print('Range of prices: ' + os.linesep + '$' + str(data['SalePrice'].min()) + ' - $' + str(data['SalePrice'].max()))\n",
    "print('Mean: $' + \"{:.2f}\".format(data['SalePrice'].mean()))\n",
    "print('Median: $' + \"{:.2f}\".format(data['SalePrice'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Alley Types:')\n",
    "for row in data['Alley'].unique():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gravel: ' +str(len(data[data['Alley'] == 'Grvl'])))\n",
    "print('Pavement: ' +str(len(data[data['Alley'] == 'Pave'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gravel: $' + \"{:,.2f}\".format(np.min(data[data['Alley'] == 'Grvl']['SalePrice']))+ ' - ' \"{:,.2f}\".format(np.max(data[data['Alley'] == 'Grvl']['SalePrice'])))\n",
    "print('Pavement: $' + \"{:,.2f}\".format(np.mean(data[data['Alley'] == 'Pave']['SalePrice'])))\n",
    "print('No Alley: $' + \"{:,.2f}\".format(np.mean(data[data['Alley'].isin([np.nan])]['SalePrice'])))\n",
    "#Similar to fences, I'm going to make a couple of hypotheses, namely that the alley\n",
    "#type corresponds in some way to the age of homes, ie those with gravel are older and, \n",
    "#second, that the homes with alleys that are paved correspond with zoning in some way. \n",
    "#ie. more densely populated areas, such as urban zones. I will verify this.\n",
    "print('Average year built and most frequent zone for gravel: ' +str(np.mean(data[data['Alley'] == 'Grvl']['YearBuilt'])))\n",
    "print('Average year built and most frequent zone for paved: ' +str(np.mean(data[data['Alley'] == 'Pave']['YearBuilt'])))\n",
    "print('Zones grouped by alley type:' + os.linesep)\n",
    "print(data.groupby('Alley')['MSZoning'].value_counts())\n",
    "#It turns out my second hypothesis was incorrect, there are more alleys, period, in low and medium density zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What types of streets exist in the dataset? \n",
    "print('Street Types:')\n",
    "for row in data['Street'].unique():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is there much variation in the type of street?\n",
    "print('Gravel: ' +str(len(data[data['Street'] == 'Grvl'])))\n",
    "print('Pavement: ' +str(len(data[data['Street'] == 'Pave'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the difference between the average price of a home by street type?\n",
    "print('Gravel: $' + \"{:,.2f}\".format(np.mean(data[data['Street'] == 'Grvl']['SalePrice'])))\n",
    "print('Pavement: $' + \"{:,.2f}\".format(np.mean(data[data['Street'] == 'Pave']['SalePrice'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the range of these values?\n",
    "print('Min:' + os.linesep*2 + 'Gravel: $' + \"{:,.2f}\".format(np.min(data[data['Street'] == 'Grvl']['SalePrice'])))\n",
    "print('Pavement: $' + \"{:,.2f}\".format(np.min(data[data['Street'] == 'Pave']['SalePrice'])))\n",
    "print(os.linesep + 'Max:' + os.linesep*2 + 'Gravel: $' + \"{:,.2f}\".format(np.max(data[data['Street'] == 'Grvl']['SalePrice'])))\n",
    "print('Pavement: $' + \"{:,.2f}\".format(np.max(data[data['Street'] == 'Pave']['SalePrice'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "#I think central air is probably important, but it may not be. The region may not \n",
    "#require air conditioning, or maybe most homes will have it. I think this could \n",
    "#be one to look at, but I want to see the split here.\n",
    "print('The average price for the ' + str(data[data['CentralAir'] == 'Y']['SalePrice'].count()) \\\n",
    "    + ' homes with central air is: $'\\\n",
    "    + \"{:.2f}\".format(data[data['CentralAir'] == 'Y']['SalePrice'].mean())\\\n",
    "    + '.' + os.linesep*2 \\\n",
    "    + 'The average price for the '+ str(data[data['CentralAir'] == 'N']['SalePrice'].count()) \\\n",
    "    + ' homes with central air is: $' \\\n",
    "    + \"{:.2f}\".format(data[data['CentralAir'] == 'N']['SalePrice'].mean()))\n",
    "#As I suspected, the price difference is quite dramatic. My guess is that the homes without central\n",
    "#air are perhaps smaller, and other differences will explain the difference in mean price. A central\n",
    "#air system doesn't cost $80,000. I will drop this column.\n",
    "data.drop(columns=['CentralAir'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reexamine null columns\n",
    "find_null_columns = {}\n",
    "for column in data.columns:\n",
    "    if(len(data[data[column].isnull()]) > 0):\n",
    "        find_null_columns[column] = len(data[data[column].isnull()])\n",
    "print('Number of null values:' + os.linesep)\n",
    "for k,v in sorted(find_null_columns.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(k + ': ' + str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next I need to start assigning values to those that are null. I will begin with Alleys. This is an object, \n",
    "#so I will use the word None in place of null values.\n",
    "data['Alley'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "print(data[data['Alley'] == 'None']['Alley'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeeeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will do the same thing as above now with the remaining string types.\n",
    "data['FireplaceQu'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "print(data[data['FireplaceQu'] == 'None']['FireplaceQu'])\n",
    "#LotFrontage is unnecessarily a float value, so I will convert it to an integer.\n",
    "data['LotFrontage'].replace(to_replace=np.nan, value=0.0, inplace=True)\n",
    "print(data[data['LotFrontage'] == np.nan]['LotFrontage'])\n",
    "data['LotFrontage'] = data['LotFrontage'].astype('int')\n",
    "print(data['LotFrontage'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['GarageCond'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['GarageQual'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['GarageFinish'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['GarageType'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "#I'm going to remove the garage year built column, because the years will be \n",
    "#difficult to analyze, and the year built should in most cases be the same as \n",
    "#the year the home was built. I will replace it with a column GarageOriginal\n",
    "#if there are a good portion, say > 10% where these values don't match.\n",
    "cond = data['GarageYrBlt'] == data['YearBuilt']\n",
    "data['GarageOrig'] = 'Y' if np.where(cond) else 'N'\n",
    "data.drop(columns=['GarageYrBlt'], inplace=True)\n",
    "print(data['GarageOrig'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['GarageQual'].unique())\n",
    "print(data[data['GarageQual'] == 'TA']['GarageQual'].count())\n",
    "#So I know that the great majority of Garages are considered to be of average quality.\n",
    "#How many are above average?\n",
    "print(data[data['GarageQual'].isin(['Ex','Gd'])]['GarageQual'].count())\n",
    "#Let's take a closer look at the sales price by quality in a scatter plot.\n",
    "data.plot(x='GarageQual', y='SalePrice', kind='scatter')\n",
    "plt.show()\n",
    "#This data isn't very meaningful. I want to see scatterplots of other quality variables to compare.\n",
    "data.plot(x='FireplaceQu', y='SalePrice', kind='scatter')\n",
    "plt.show()\n",
    "#Outliers skew the data, but overall there is a correlation between both garage and fireplace quality,\n",
    "#and SalePrice. I'm not convinced that they will justify a meaningful increase in sale price, however\n",
    "#I will keep them for the time being.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f02656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm going to continue replacing null values now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34360ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['MSSubClass']==45]['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dad584",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns = data.columns[data.isna().any()].tolist()\n",
    "for col in null_columns:\n",
    "    print(data[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MasVnrType'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['BsmtQual'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['BsmtCond'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['BsmtExposure'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['BsmtFinType1'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['BsmtFinType2'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['Electrical'].replace(to_replace=np.nan, value='None', inplace=True)\n",
    "data['MasVnrArea'].replace(to_replace=np.nan, value=0.0, inplace=True)\n",
    "print(data[data['MasVnrArea'] > 2]['MasVnrArea'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[data.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68567dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:15][['GarageQual','GarageFinish','GarageType','GarageCond']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data'\n",
    "save_file(data, 'house_data_cleaned.csv', datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f83bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30eb47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
